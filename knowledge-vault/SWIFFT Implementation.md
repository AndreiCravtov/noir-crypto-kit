The implementation uses two main techniques for achieving high performance, both relating to the structure of the Fast Fourier Transform (FFT) algorithm. The first observation is that the input to the FFT is a ***binary vector***, which limits the number of possible input values (when restricting our view to a small portion of the input). This allows us to ***precompute*** and store the results of several initial iterations of the FFT in a lookup table. The second observation is that the FFT algorithm consists of operations repeated in ***parallel*** over many pieces of data, for which modern microprocessors have special-purpose instruction sets.

Recall the parameters $n=64, m=16$ and modulus $p = 257$. Let $\omega$ be a $128$-th root of unity in $\mathbb{Z}_{p} = \mathbb{Z}_{257}$, i.e. an element of order $128 = 2n$; we will see later that it is convenient to choose $\omega=42$, but most of the discussion is independent from the choice of $\omega=42$. The compression function takes an $mn = 1024$-bit input, viewed as $m = 16$ binary vectors $\mathbf{x}_{0},...,\mathbf{x}_{15} ∈ \{0, 1\}^{64}$. (For convenience, entries of a vector or sequence are numbered starting from $0$ throughout this section.) The function first processes each vector $\mathbf{x}_{j}$ by multiplying it's $i$-th entry by $\omega^i \ \ (0\leq i \leq63)$, and then computing the Fourier transform of the resulting vector using $\omega^2$ as a $64$-th root of unity. More precisely, each input vector $\mathbf{x}_{j} \in \{0, 1\}^{64}$ is mapped to $\mathbf{y}_{j} = F(\mathbf{x}_{j}) \in \mathbb{Z}_{257}^{64}$, where $F: \{ 0,1 \}^{64} \to \mathbb{Z}_{257}^{64}$ is the function
$$\large
F(\mathbf{x})_{i} = \sum_{k = 0}^{63} (x_{k} \cdot \omega^k) \cdot (\omega^2)^{i \cdot k} = \sum_{k=0}^{63} = x_{k} \cdot \omega^{(2i + 1)k}
$$
The final output $\mathbf{z}$ of the compression function is then obtained by computing $64$ distinct linear combinations (modulo $257$) across corresponding $i$-th entries of the 16 $\mathbf{y}_{j}$ vectors:
$$\large
z_{i} = \sum_{j=0}^{15} a_{ij} \cdot y_{ij} \mod 257
$$
where the $a_{ij} \in \mathbb{Z}_{257}$ are the primitive Fourier coefficients of the fixed multipliers.

The most expensive part of the computation is clearly the computation of the transformation $F$ on the 16 input vectors $\mathbf{x}_{}j$ , so we first focus on the efficient computation of $F$. Let $\mathbf{y} = F(\mathbf{x}) \in \large \mathbb{Z}^{64}_{257}$ for some $\mathbf{x} \in \{0, 1\}^{64}$. Expressing the indices $0\leq i,k \leq 63$ in ***octal*** as $i = i_{0}0+8i_{1}$ and $k = k_0+8k_1$ (where $j_0, j_1, k_0, k_1 \in \{0,\dots, 7\}$), and using $\omega^{128} = 1 \mod 257$, the $i$-th component of $\mathbf{y} = F(\mathbf{x})$ is seen to equal
$$\Large
\begin{align}
y_{i_{0} + 8 i_{1}} &= \sum_{k_{0}=0}^7 (\omega^{16})^{i_{1} \cdot k_{0}} \left( \omega^{(2i_{0} + 1)k_{0}} \cdot \sum_{k_{1}=0}^7 \omega^{8k_{1}(2_{i_{0}} + 1)} \cdot x_{k_{0} + 8_{k_{1}}} \right) \\
&= \sum_{k_{0}=0}^{7} (\omega^{16})^{i_{1} \cdot k_{0}} \cdot (m_{k_{0},i_{0}} \cdot t_{k_{0},i_{0}})
\end{align}
$$
where $\large m_{k_{0},i_{0}} = \omega^{(2i_{0} + 1)k_{0}}$ and $\large t_{k_{0},i_{0}} = \sum_{k_{1}=0}^7 \omega^{8k_{1}(2i_{0}+1)}x_{k_{0}+8k_{1}}$. Our first observation is that each $8$-dimensional vector $\large \mathbf{t}_{k_{0}} = (t_{k_{0},0}, t_{k_{0},1}, \dots, t_{k_{0},7})$ can take only $256$ possible values, depending on the corresponding input bits $\large x_{k_0} , x_{k_0 + 8}, \dots,x_{k_0 + 8 \cdot 7}$. Our implementation parses each $64$-bit block of the input as a sequence of $8$ bytes $X_{1},\dots,X_{7}$, where $\large X_{k_{0}} = (x_{k_0} , x_{k_0 + 8}, \dots,x_{k_0 + 8 \cdot 7} ) \in \{0, 1\}^8$, so that each vector $\large \mathbf{t}_{k_{0}}$ can be found with just a single table look-up operation $\large \mathbf{t}_{k_{0}} = T(X_{k_0} )$, using a table $T$ with $256$ entries. The multipliers $\large \mathbf{m}_{k_0} = (m_{k_0,0},\dots,m_{k_0,7})$ can also be precomputed.

The value $\mathbf{y} = F(\mathbf{x})$ can be broken down as 8 (8-dimensional) vectors
$$\Large\mathbf{y}_{i_{1}} = (y_{8i_{1}}, y_{8i_{1} +1}, \dots, y_{8i_{1}+7}) \in \mathbb{Z}_{257}^{8}$$
Our second observation is that, for any $i_{0} = 0,\dots,7$, the $\large i_0$-th component of $\large\mathbf{y}_{i_{1}}$ depends only on the $\large i_0$-th components of $\large \mathbf{m}_{k_0}$ and $\large \mathbf{t}_{k_{0}}$. Moreover, the operations performed for every coordinate are exactly the same. This permits parallelizing the computation of the output vectors $\mathbf{y}_{0}, \dots, \mathbf{y}_{7}$ using SIMD (single-instruction multiple-data) instructions commonly found on modern microprocessors. For example, Intel’s microprocessors (starting from the Pentium 4) include a set of so-called SSE2 instructions that allow operations on a set of special registers each holding an 8-dimensional vector with 16-bit (signed) integer components. We only use the most common SIMD instructions (e.g., component-wise addition and multiplication of vectors), which are also found on most other modern microprocessors, e.g., as part of the AltiVec SIMD instruction set of the Motorola G4 and IBM G5 and POWER6. In the rest of this section, operations on $8$-dimensional vectors like $\large \mathbf{m}_{k_0}$ and $\large \mathbf{t}_{k_{0}}$ are interpreted as *scalar* operations applied component-wise to the vectors, possibly in parallel using a single SIMD instruction.

Going back to the computation of $F(\mathbf{x})$, the output vectors $\large\mathbf{y}_{i_1}$ can be expressed as
$$\Large\mathbf{y}_{i_{1}} = \sum_{k_{0}=0}^{7} (\omega^{16})^{i_{1} \cdot k_{0}} \cdot (\mathbf{m}_{k_{0}} \cdot \mathbf{t}_{k_{0}})$$
Our third observation is that the latter computation is just a sequence of $8$ component-wise multiplications $\large \mathbf{m}_{k_{0}} \cdot \mathbf{t}_{k_{0}}$ , followed by a single 8-dimensional Fourier transform using $\omega^{16}$ as an $8$-th root of unity in $\large \mathbb{Z}_{257}$. The latter can be efficiently implemented using a standard FFT network consisting of just 12 additions, 12 subtractions and 5 multiplications.

Optimisations relating to $\mathbb{Z}_{257}$. One last source of optimisation comes from two more observations that are specific to the use of $257$ as a modulus, and the choice of $\omega = 42$ as a $128$-th root of unity. One observation is that the root used in the $8$-dimensional FFT computation equals $\omega^{16} = 22 \mod 257$. So, multiplication by $(\omega^{16}),(\omega{16})2 \ \text{and} \ (\omega^{16})^3$, as required by the FFT, can be simply implemented as left bit-shift operations (by 2, 4, and 6 positions, respectively). Moreover, analysis of the FFT network shows that modular reduction can be avoided (without the risk of overflow using 16-bit arithmetic) for most of the intermediate values. Specifically, in our implementation, modular reduction is performed for only $3$ of the intermediate values. The last observation is that, even when necessary to avoid overflow, reduction modulo $257$ can be implemented rather cheaply and using common SIMD instructions, e.g., a $16$-bit (signed) integer can be reduced to the range $\{−127, \dots, 383\}$ using $x \equiv (x \wedge 255) − (x \gg 8) \mod 257$, where $\wedge$ is the bit-wise “and” operation, and $\gg 8$ is a right-shift by $8$ bits.

Summary and performance. In summary, function $F$ can be computed with just a handful of table look-ups and simple SIMD instructions on $8$-dimensional vectors. The implementation of the remaining part of the computation of the compression function (i.e., the scalar products between $y_{i,j}$ and $a_{i,j}$) is straightforward, keeping in mind that this part of the computation can also be parallelized using SIMD instructions, and that reduction modulo $257$ is rarely necessary during the intermediate steps of the computation due to the use of 16-bit (or larger) registers.

Further optimisations. We remark that our implementation does not yet take advantage of all the potential for parallelism. In particular, we only exploited SIMD-level parallelism in individual evaluations of the transformation function $F$. Each evaluation of the compression function involves 16 applications of $F$, and subsequent multiplication of the result by the coefficients $a_{i,j}$. These 16 computations are completely independent, and can be easily executed in parallel on a multicore microprocessor. Our profiling data shows that the FFT computations and multiplication by $a_{i,j}$ currently account for about 90% of the running time. So, as multicore processors become more common, and the number of cores available on a processor increases, one can expect the speed of our function to grow almost proportionally to the number of cores, at least up to 16 cores. Finally, we point out that FFT networks are essentially “optimally parallelizable,” and that our compression function has extremely small circuit depth, allowing it to be computed extremely fast in customized hardware.